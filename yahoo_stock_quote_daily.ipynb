{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSG7Apt69DWqik0/vCYbv9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leonloveu/googlecolab_stocks/blob/main/yahoo_stock_quote_daily.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "!pip install pandas_datareader\n",
        "!pip install matplotlib\n",
        "!pip install psycopg2-binary python-dotenv\n",
        "\n",
        "# prompt: pip3 install ta_lib\n",
        "\n",
        "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "!tar xvzf ta-lib-0.4.0-src.tar.gz\n",
        "import os\n",
        "os.chdir('ta-lib')\n",
        "!./configure --prefix=/usr\n",
        "!make\n",
        "!make install\n",
        "!pip install Ta-Lib"
      ],
      "metadata": {
        "id": "OfyUvUjsPQ9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr2z5YS1Wvo4"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine  # SQL database interaction\n",
        "import pandas as pd  # Data manipulation and analysis\n",
        "from pandas_datareader import data as pdr  # Data retrieval for financial data\n",
        "import yfinance as yf  # Yahoo Finance API for financial data\n",
        "from datetime import datetime, timedelta  # Date and time handling\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "warnings.filterwarnings('ignore',category=Warning)\n",
        "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import os.path\n",
        "import talib as ta\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from datetime import timedelta, datetime\n",
        "from dateutil import parser\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.dates import DateFormatter\n",
        "from matplotlib.dates import DayLocator\n",
        "from matplotlib.dates import MonthLocator\n",
        "import matplotlib.ticker as mticker\n",
        "import matplotlib.mlab as mlab\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "plt.rcParams.update({'figure.figsize':(15,8), 'figure.dpi':120})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make dataframe output easier to read\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.width', None)  # Allow horizontal scrolling\n",
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "\n",
        "# Import NASDAQ stock tickers that will loop through the yfinance library - to collect stock history data\n",
        "url_nasdaq = \"https://www.nasdaqtrader.com/dynamic/SymDir/nasdaqlisted.txt\"\n",
        "nasdaq_symbols_df = pd.read_csv(url_nasdaq, sep='|')\n",
        "nasdaq_symbols = nasdaq_symbols_df['Symbol'].tolist()\n",
        "\n",
        "nasdaq_symbols"
      ],
      "metadata": {
        "id": "ZZJSNcqaQRi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make dataframe output easier to read\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.width', None)  # Allow horizontal scrolling\n",
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "\n",
        "# Create dataframe containing GOOGL's price history per day for 2023 YTD\n",
        "sample_data = yf.download('GOOGL', start='2023-01-01', end='2023-12-31')\n",
        "sample_data.sort_values(by=['Date'], inplace=True, ascending=False)\n",
        "sample_data.reset_index(inplace=True)\n",
        "sample_data.head()\n",
        "sample_data_df = pd.DataFrame(sample_data)\n",
        "\n",
        "# Print sample data\n",
        "sample_data_df\n",
        "\n",
        "#OUTPUT_FOLDER = '/content/'\n",
        "#sample_data_df.to_csv(OUTPUT_FOLDER + 'historical_data.csv', mode='a', index=False, header=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F7Z0CkiuRHX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startDate = pd.to_datetime('today') - 30 * pd.Timedelta(days=1)\n",
        "endDate = pd.to_datetime('today')\n",
        "\n",
        "\n",
        "print(startDate)\n",
        "print(endDate)"
      ],
      "metadata": {
        "id": "gP7ftttJF1wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_data_df = pd.DataFrame()\n",
        "historical_data_df.head()"
      ],
      "metadata": {
        "id": "JEdhNjSVCVOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ifon1YMwCbcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker in nasdaq_symbols:\n",
        "    try:\n",
        "        # Attempt to download data for the last 5 years\n",
        "        data = yf.download(ticker, start=startDate, end=endDate)\n",
        "\n",
        "        # Drop and Add a new column for the ticker symbol\n",
        "        data.drop(['Adj Close'], axis=1, inplace=True)\n",
        "\n",
        "        data['Symbol'] = ticker\n",
        "        data.sort_values(by=['Date'], inplace=True, ascending=False)\n",
        "        data.reset_index(inplace=True)\n",
        "        historical_data_df = pd.DataFrame(data)\n",
        "\n",
        "        print(f\"Downloaded data for {ticker}\")\n",
        "        OUTPUT_FOLDER = '/content/'\n",
        "        historical_data_df.to_csv(OUTPUT_FOLDER + 'historical_data.csv', mode='a', index=False, header=False)\n",
        "        historical_data_df.head()\n",
        "\n",
        "    except Exception:\n",
        "        # Suppress all error messages and continue with the next iteration\n",
        "        continue\n",
        "\n",
        "# Print the first few rows of the combined DataFrame\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "diKIhlM5A8GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crypto = pd.read_csv(\"/content/historical_data.csv\", names=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Symbol'], parse_dates=True)\n",
        "#crypto.head()\n",
        "\n",
        "for ticker in nasdaq_symbols:\n",
        "    try:\n",
        "      crypto = pd.read_csv(\"/content/historical_data.csv\", names=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Symbol'], parse_dates=True)\n",
        "      head_aacg = crypto[crypto[\"Symbol\"] == ticker]\n",
        "      print(ticker)\n",
        "      head_aacg = head_aacg[[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n",
        "      print(head_aacg.head())\n",
        "      head_aacg.head()\n",
        "    except Exception:\n",
        "      continue\n",
        "\n",
        "head_aacg.head()"
      ],
      "metadata": {
        "id": "y1Gqi4ZUhiLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import talib\n",
        "candle_names = talib.get_function_groups()['Pattern Recognition']\n",
        "removed = ['CDLCOUNTERATTACK', 'CDLLONGLINE', 'CDLSHORTLINE',\n",
        "           'CDLSTALLEDPATTERN', 'CDLKICKINGBYLENGTH']\n",
        "candle_names = [name for name in candle_names if name not in removed]"
      ],
      "metadata": {
        "id": "Ud2avdKWXt7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "', '.join(candle_names)"
      ],
      "metadata": {
        "id": "G-PCQg64XzLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candle_rankings = {\n",
        "        \"CDL3LINESTRIKE_Bull\": 1,\n",
        "        \"CDL3LINESTRIKE_Bear\": 2,\n",
        "        \"CDL3BLACKCROWS_Bull\": 3,\n",
        "        \"CDL3BLACKCROWS_Bear\": 3,\n",
        "        \"CDLEVENINGSTAR_Bull\": 4,\n",
        "        \"CDLEVENINGSTAR_Bear\": 4,\n",
        "        \"CDLTASUKIGAP_Bull\": 5,\n",
        "        \"CDLTASUKIGAP_Bear\": 5,\n",
        "        \"CDLINVERTEDHAMMER_Bull\": 6,\n",
        "        \"CDLINVERTEDHAMMER_Bear\": 6,\n",
        "        \"CDLMATCHINGLOW_Bull\": 7,\n",
        "        \"CDLMATCHINGLOW_Bear\": 7,\n",
        "        \"CDLABANDONEDBABY_Bull\": 8,\n",
        "        \"CDLABANDONEDBABY_Bear\": 8,\n",
        "        \"CDLBREAKAWAY_Bull\": 10,\n",
        "        \"CDLBREAKAWAY_Bear\": 10,\n",
        "        \"CDLMORNINGSTAR_Bull\": 12,\n",
        "        \"CDLMORNINGSTAR_Bear\": 12,\n",
        "        \"CDLPIERCING_Bull\": 13,\n",
        "        \"CDLPIERCING_Bear\": 13,\n",
        "        \"CDLSTICKSANDWICH_Bull\": 14,\n",
        "        \"CDLSTICKSANDWICH_Bear\": 14,\n",
        "        \"CDLTHRUSTING_Bull\": 15,\n",
        "        \"CDLTHRUSTING_Bear\": 15,\n",
        "        \"CDLINNECK_Bull\": 17,\n",
        "        \"CDLINNECK_Bear\": 17,\n",
        "        \"CDL3INSIDE_Bull\": 20,\n",
        "        \"CDL3INSIDE_Bear\": 56,\n",
        "        \"CDLHOMINGPIGEON_Bull\": 21,\n",
        "        \"CDLHOMINGPIGEON_Bear\": 21,\n",
        "        \"CDLDARKCLOUDCOVER_Bull\": 22,\n",
        "        \"CDLDARKCLOUDCOVER_Bear\": 22,\n",
        "        \"CDLIDENTICAL3CROWS_Bull\": 24,\n",
        "        \"CDLIDENTICAL3CROWS_Bear\": 24,\n",
        "        \"CDLMORNINGDOJISTAR_Bull\": 25,\n",
        "        \"CDLMORNINGDOJISTAR_Bear\": 25,\n",
        "        \"CDLXSIDEGAP3METHODS_Bull\": 27,\n",
        "        \"CDLXSIDEGAP3METHODS_Bear\": 26,\n",
        "        \"CDLTRISTAR_Bull\": 28,\n",
        "        \"CDLTRISTAR_Bear\": 76,\n",
        "        \"CDLGAPSIDESIDEWHITE_Bull\": 46,\n",
        "        \"CDLGAPSIDESIDEWHITE_Bear\": 29,\n",
        "        \"CDLEVENINGDOJISTAR_Bull\": 30,\n",
        "        \"CDLEVENINGDOJISTAR_Bear\": 30,\n",
        "        \"CDL3WHITESOLDIERS_Bull\": 32,\n",
        "        \"CDL3WHITESOLDIERS_Bear\": 32,\n",
        "        \"CDLONNECK_Bull\": 33,\n",
        "        \"CDLONNECK_Bear\": 33,\n",
        "        \"CDL3OUTSIDE_Bull\": 34,\n",
        "        \"CDL3OUTSIDE_Bear\": 39,\n",
        "        \"CDLRICKSHAWMAN_Bull\": 35,\n",
        "        \"CDLRICKSHAWMAN_Bear\": 35,\n",
        "        \"CDLSEPARATINGLINES_Bull\": 36,\n",
        "        \"CDLSEPARATINGLINES_Bear\": 40,\n",
        "        \"CDLLONGLEGGEDDOJI_Bull\": 37,\n",
        "        \"CDLLONGLEGGEDDOJI_Bear\": 37,\n",
        "        \"CDLHARAMI_Bull\": 38,\n",
        "        \"CDLHARAMI_Bear\": 72,\n",
        "        \"CDLLADDERBOTTOM_Bull\": 41,\n",
        "        \"CDLLADDERBOTTOM_Bear\": 41,\n",
        "        \"CDLCLOSINGMARUBOZU_Bull\": 70,\n",
        "        \"CDLCLOSINGMARUBOZU_Bear\": 43,\n",
        "        \"CDLTAKURI_Bull\": 47,\n",
        "        \"CDLTAKURI_Bear\": 47,\n",
        "        \"CDLDOJISTAR_Bull\": 49,\n",
        "        \"CDLDOJISTAR_Bear\": 51,\n",
        "        \"CDLHARAMICROSS_Bull\": 50,\n",
        "        \"CDLHARAMICROSS_Bear\": 80,\n",
        "        \"CDLADVANCEBLOCK_Bull\": 54,\n",
        "        \"CDLADVANCEBLOCK_Bear\": 54,\n",
        "        \"CDLSHOOTINGSTAR_Bull\": 55,\n",
        "        \"CDLSHOOTINGSTAR_Bear\": 55,\n",
        "        \"CDLMARUBOZU_Bull\": 71,\n",
        "        \"CDLMARUBOZU_Bear\": 57,\n",
        "        \"CDLUNIQUE3RIVER_Bull\": 60,\n",
        "        \"CDLUNIQUE3RIVER_Bear\": 60,\n",
        "        \"CDL2CROWS_Bull\": 61,\n",
        "        \"CDL2CROWS_Bear\": 61,\n",
        "        \"CDLBELTHOLD_Bull\": 62,\n",
        "        \"CDLBELTHOLD_Bear\": 63,\n",
        "        \"CDLHAMMER_Bull\": 65,\n",
        "        \"CDLHAMMER_Bear\": 65,\n",
        "        \"CDLHIGHWAVE_Bull\": 67,\n",
        "        \"CDLHIGHWAVE_Bear\": 67,\n",
        "        \"CDLSPINNINGTOP_Bull\": 69,\n",
        "        \"CDLSPINNINGTOP_Bear\": 73,\n",
        "        \"CDLUPSIDEGAP2CROWS_Bull\": 74,\n",
        "        \"CDLUPSIDEGAP2CROWS_Bear\": 74,\n",
        "        \"CDLGRAVESTONEDOJI_Bull\": 77,\n",
        "        \"CDLGRAVESTONEDOJI_Bear\": 77,\n",
        "        \"CDLHIKKAKEMOD_Bull\": 82,\n",
        "        \"CDLHIKKAKEMOD_Bear\": 81,\n",
        "        \"CDLHIKKAKE_Bull\": 85,\n",
        "        \"CDLHIKKAKE_Bear\": 83,\n",
        "        \"CDLENGULFING_Bull\": 84,\n",
        "        \"CDLENGULFING_Bear\": 91,\n",
        "        \"CDLMATHOLD_Bull\": 86,\n",
        "        \"CDLMATHOLD_Bear\": 86,\n",
        "        \"CDLHANGINGMAN_Bull\": 87,\n",
        "        \"CDLHANGINGMAN_Bear\": 87,\n",
        "        \"CDLRISEFALL3METHODS_Bull\": 94,\n",
        "        \"CDLRISEFALL3METHODS_Bear\": 89,\n",
        "        \"CDLKICKING_Bull\": 96,\n",
        "        \"CDLKICKING_Bear\": 102,\n",
        "        \"CDLDRAGONFLYDOJI_Bull\": 98,\n",
        "        \"CDLDRAGONFLYDOJI_Bear\": 98,\n",
        "        \"CDLCONCEALBABYSWALL_Bull\": 101,\n",
        "        \"CDLCONCEALBABYSWALL_Bear\": 101,\n",
        "        \"CDL3STARSINSOUTH_Bull\": 103,\n",
        "        \"CDL3STARSINSOUTH_Bear\": 103,\n",
        "        \"CDLDOJI_Bull\": 104,\n",
        "        \"CDLDOJI_Bear\": 104\n",
        "    }"
      ],
      "metadata": {
        "id": "n_i1NC7WZ7Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crypto.reset_index(inplace=True)\n",
        "crypto = crypto[['Date', 'Open', 'High', 'Low', 'Close']]\n",
        "crypto.columns = ['time', 'open', 'high', 'low', 'close']"
      ],
      "metadata": {
        "id": "mdyRzW1rX7d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanPx(prices, freq='1D'):\n",
        "    if prices.empty:\n",
        "        return prices  # Return the empty DataFrame if it's empty\n",
        "\n",
        "    # Convert 'Date' to datetime and handle potential errors\n",
        "    try:\n",
        "        prices.Date = pd.to_datetime(prices.Date)\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting 'Date' column: {e}\")\n",
        "        return prices  # Or handle the error in a more appropriate way\n",
        "\n",
        "    #prices = prices.iloc[prices.Date.drop_duplicates(keep='last').index]\n",
        "    prices = prices[~prices.Date.duplicated(keep='last')]\n",
        "    #prices.Date = pd.to_datetime(prices.Date)\n",
        "    prices.set_index('Date', inplace=True)\n",
        "\n",
        "    prices_ohlc = prices[['Open','High','Low','Close']]\n",
        "    prices_vol = prices[['Volume']]\n",
        "    prices_symbols = prices[['Symbol']]\n",
        "    #prices_Date = prices[['Date']]\n",
        "    #print(prices_symbols)\n",
        "\n",
        "    prices_ohlc = prices_ohlc.resample(freq).agg({'Open': 'first',\n",
        "                                 'High': 'max',\n",
        "                                 'Low': 'min',\n",
        "                                 'Close': 'last'})\n",
        "    prices_vol = prices_vol.resample(freq).sum()\n",
        "    prices_symbols = prices_symbols.resample(freq).last()\n",
        "    #print(prices_symbols)\n",
        "\n",
        "    prices = pd.concat([prices_ohlc, prices_vol, prices_symbols], axis=1)\n",
        "    prices.index = prices.index.tz_localize('UTC').tz_convert('Asia/Singapore')\n",
        "\n",
        "    return prices.dropna()"
      ],
      "metadata": {
        "id": "wEMMxdBkAPJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crypto = pd.read_csv(\"/content/historical_data.csv\", names=['Date', 'Open', 'High', 'Low', 'Close', 'Symbol'], parse_dates=True)\n",
        "\n",
        "for ticker in nasdaq_symbols:\n",
        "    #try:\n",
        "      crypto_org = pd.read_csv(\"/content/historical_data.csv\", names=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Symbol'], parse_dates=True)\n",
        "      crypto = crypto_org[crypto_org[\"Symbol\"] == ticker]\n",
        "\n",
        "      if not crypto.empty:\n",
        "        crypto = cleanPx(crypto, '1D')\n",
        "        #crypto.reset_index(inplace=True)\n",
        "        #crypto.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Symbol']\n",
        "        #crypto.set_index('Date', inplace=True)\n",
        "        crypto_csv_df = pd.DataFrame(crypto)\n",
        "        crypto_csv_df.reset_index(inplace=True)\n",
        "        crypto_csv_df.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Symbol']\n",
        "        #crypto_csv_df.set_index('Date', inplace=True)\n",
        "        print(crypto_csv_df.head())\n",
        "\n",
        "        OUTPUT_FOLDER = '/content/'\n",
        "        crypto_csv_df.to_csv(OUTPUT_FOLDER + 'crypto.csv', mode='a', index=False, header=False)\n",
        "\n",
        "\n",
        "      #crypto\n",
        "      #print(crypto.head())\n",
        "\n",
        "\n",
        "    #except Exception:\n",
        "      #continue"
      ],
      "metadata": {
        "id": "XiOvueQ7DXvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract OHLC\n",
        "crypto_csv = pd.read_csv(\"/content/crypto.csv\", names=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Symbol'], parse_dates=True)\n",
        "#print(crypto_csv.head())\n",
        "#crypto_csv.reset_index(inplace=True)\n",
        "crypto_csv = crypto_csv[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Symbol']]\n",
        "crypto_csv.columns = ['time', 'open', 'high', 'low', 'close', 'Volume', 'Symbol']\n",
        "\n",
        "op = crypto_csv['open']\n",
        "hi = crypto_csv['high']\n",
        "lo = crypto_csv['low']\n",
        "cl = crypto_csv['close']\n",
        "\n",
        "# create columns for each pattern\n",
        "for candle in candle_names:\n",
        "    # below is same as;\n",
        "    # df[\"CDL3LINESTRIKE\"] = talib.CDL3LINESTRIKE(op, hi, lo, cl)\n",
        "    crypto_csv[candle] = getattr(talib, candle)(op, hi, lo, cl)"
      ],
      "metadata": {
        "id": "gjLRogJOZRaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import compress\n",
        "\n",
        "crypto_csv['candlestick_pattern'] = np.nan\n",
        "crypto_csv['candlestick_match_count'] = np.nan\n",
        "\n",
        "for index, row in crypto_csv.iterrows():\n",
        "\n",
        "    # no pattern found\n",
        "    if len(row[candle_names]) - sum(row[candle_names] == 0) == 0:\n",
        "        crypto_csv.loc[index,'candlestick_pattern'] = \"NO_PATTERN\"\n",
        "        crypto_csv.loc[index, 'candlestick_match_count'] = 0\n",
        "    # single pattern found\n",
        "    elif len(row[candle_names]) - sum(row[candle_names] == 0) == 1:\n",
        "        # bull pattern 100 or 200\n",
        "        if any(row[candle_names].values > 0):\n",
        "            pattern = list(compress(row[candle_names].keys(), row[candle_names].values != 0))[0] + '_Bull'\n",
        "            crypto_csv.loc[index, 'candlestick_pattern'] = pattern\n",
        "            crypto_csv.loc[index, 'candlestick_match_count'] = 1\n",
        "        # bear pattern -100 or -200\n",
        "        else:\n",
        "            pattern = list(compress(row[candle_names].keys(), row[candle_names].values != 0))[0] + '_Bear'\n",
        "            crypto_csv.loc[index, 'candlestick_pattern'] = pattern\n",
        "            crypto_csv.loc[index, 'candlestick_match_count'] = 1\n",
        "    # multiple patterns matched -- select best performance\n",
        "    else:\n",
        "        # filter out pattern names from bool list of values\n",
        "        patterns = list(compress(row[candle_names].keys(), row[candle_names].values != 0))\n",
        "        container = []\n",
        "        for pattern in patterns:\n",
        "            if row[pattern] > 0:\n",
        "                container.append(pattern + '_Bull')\n",
        "            else:\n",
        "                container.append(pattern + '_Bear')\n",
        "        rank_list = [candle_rankings[p] for p in container]\n",
        "        if len(rank_list) == len(container):\n",
        "            rank_index_best = rank_list.index(min(rank_list))\n",
        "            crypto_csv.loc[index, 'candlestick_pattern'] = container[rank_index_best]\n",
        "            crypto_csv.loc[index, 'candlestick_match_count'] = len(container)"
      ],
      "metadata": {
        "id": "xPnxCKcNpf3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up candle columns\n",
        "try:\n",
        "    crypto_csv.drop(candle_names, axis = 1, inplace = True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "crypto_csv.loc[crypto_csv.candlestick_pattern == 'NO_PATTERN', 'candlestick_pattern'] = ''\n",
        "crypto_csv.candlestick_pattern = crypto_csv.candlestick_pattern.apply(lambda x: x[3:] if isinstance(x, str) else x)\n"
      ],
      "metadata": {
        "id": "bJHFyuoehwEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = '/content/'\n",
        "crypto_csv.to_csv(OUTPUT_FOLDER + 'ethusd.csv', index=False)"
      ],
      "metadata": {
        "id": "Cmdl9kO3h3jf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}